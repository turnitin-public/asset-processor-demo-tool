services:
  llamacpp-server:
    image: ghcr.io/ggml-org/llama.cpp:server
    ports:
      - 8080:8080
    volumes:
      - ./llm:/models
    environment:
      LLAMA_ARG_MODEL: /models/Llama-3.2-3B-Instruct-Q6_K.gguf
      LLAMA_ARG_CTX_SIZE: 4096
      LLAMA_ARG_N_PARALLEL: 2
      LLAMA_ARG_ENDPOINT_METRICS: 1
      LLAMA_ARG_PORT: 8080

  ap-server:
    build: .
    image: ap-server
    volumes:
      - ./ml:/modules
    ports:
      - ${LTI_SERVER_PORT:-9002}:8000
    environment:
      - DB_USER=postgres
      - DB_NAME=postgres
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_PASSWORD=postgres
      - TOKEN_SECRET=secret
      - LLM_SERVER_URL=http://llamacpp-server:8080
    depends_on:
      - postgres

  postgres:
    image: postgres:9.6.6
    volumes:
      - ./db:/docker-entrypoint-initdb.d
    ports:
    - "5422:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
      - LOG_LEVEL=DEBUG

  ngrok:
    image: ngrok/ngrok:latest
    command:
      - "http"
      - "--url"
      - "https://${NGROK_DOMAIN:-lti-asset-processor-${USER:-default}}.ngrok.io"
      - "--authtoken"
      - "${NGROK_AUTH}"
      - "--log"
      - "stdout"
      - "ap-server:8000"
    ports:
      - 40040:4040
